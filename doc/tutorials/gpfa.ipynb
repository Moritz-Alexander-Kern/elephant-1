{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: GPFA (Gaussian Process Factor Analysis)\n",
    "\n",
    "Gaussian-process factor analysis (GPFA) is a dimensionality reduction method\n",
    "[1] for neural trajectory visualization of parallel spike trains. GPFA applies\n",
    "factor analysis (FA) to time-binned spike count data to reduce the\n",
    "dimensionality and at the same time smoothes the resulting low-dimensional\n",
    "trajectories by fitting a Gaussian process (GP) model to them.\n",
    "\n",
    "The input consists of a set of trials ($Y$), each containing a list of spike\n",
    "trains (N neurons). The output is the projection ($X$) of the data in a space\n",
    "of pre-chosen dimensionality $x_{dim} < N$.\n",
    "\n",
    "Under the assumption of a linear relation (transform matrix $C$) between the\n",
    "latent variable $X$ following a Gaussian process and the spike train data $Y$ with\n",
    "a bias $d$ and a noise term of zero mean and (co)variance $R$ (i.e.,\n",
    "$Y = C X + d + \\mathcal{N}(0,R)$), the projection corresponds to the\n",
    "conditional probability $E[X|Y]$.\n",
    "The parameters $(C, d, R)$ as well as the time scales and variances of the\n",
    "Gaussian process are estimated from the data using an expectation-maximization\n",
    "(EM) algorithm.\n",
    "\n",
    "Internally, the analysis consists of the following steps:\n",
    "\n",
    "0. bin the spike train data to get a sequence of $N$ dimensional vectors of spike counts in respective time bins, and choose the reduced dimensionality $x_{dim}$\n",
    "\n",
    "1. expectation-maximization for fitting of the parameters $C, d, R$ and the time-scales and variances of the Gaussian process, using all the trials provided as input (c.f., `gpfa_core.em()`)\n",
    "\n",
    "2. projection of single trials in the low dimensional space (c.f., `gpfa_core.exact_inference_with_ll()`)\n",
    "\n",
    "3. orthonormalization of the matrix $C$ and the corresponding subspace, for visualization purposes: (c.f., `gpfa_core.orthonormalize()`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Idea of This Tutorial\n",
    "\n",
    "This tutorial illustrates the usage of the `gpfa.GPFA()` class implemented in elephant, through its applications to synthetic spike train data, of which the ground truth low-dimensional structure is known.\n",
    "\n",
    "The examples were inspired by the supplementary material of [2]\n",
    "\n",
    "### 1.1. Generation of synthetic spike trains\n",
    "\n",
    "A set of spike trains are generated as follows.\n",
    "First, a time series of either a 2-dimensional harmonic oscillator (Section 2) or a 3-dimensional Lorentz system (Section 3; the \"standard\" parameter values as seen in https://en.wikipedia.org/wiki/Lorenz_system are used) is projected into a high-dimensional space (as high dimension as the desired number of parallel spike trains) via a random projection.\n",
    "Then the resulting high-dimensional time series serves as time-dependent rates for an inhomogeneous multivariate Poisson process.\n",
    "Finally, multiple realizations of this Poisson process, which mimic spike trains from multiple trials, serve as input data to the GPFA.\n",
    "\n",
    "Below are the functions used for spike train generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12,
     40,
     73,
     104,
     133
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "\n",
    "\n",
    "def integrated_oscillator(dt, num_steps, x0=0, y0=1, angular_frequency=2*np.pi*1e-3):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dt : float\n",
    "        Integration time step in ms.\n",
    "    num_steps : int\n",
    "        Number of integration steps -> max_time = dt*(num_steps-1).\n",
    "    x0, y0 : float \n",
    "        Initial values in three dimensional space.\n",
    "    angular_frequency : float \n",
    "        Angular frequency in 1/ms.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t : (num_steps) np.ndarray\n",
    "        Array of timepoints\n",
    "    (2, num_steps) np.ndarray\n",
    "        Integrated two-dimensional trajectory (x, y, z) of the harmonic oscillator\n",
    "    \"\"\" \n",
    "    \n",
    "    assert isinstance(num_steps, int), \"num_steps has to be integer\"\n",
    "    t = dt*np.arange(num_steps)\n",
    "    x = x0*np.cos(angular_frequency*t) + y0*np.sin(angular_frequency*t)\n",
    "    y = -x0*np.sin(angular_frequency*t) + y0*np.cos(angular_frequency*t)\n",
    "    return t, np.array((x, y))\n",
    "\n",
    "\n",
    "def integrated_lorenz(dt, num_steps, x0=0, y0=1, z0=1.05,\n",
    "                      sigma=10, rho=28, beta=2.667, tau=1e3):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dt : \n",
    "        Integration time step in ms.\n",
    "    num_steps : int\n",
    "        Number of integration steps -> max_time = dt*(num_steps-1).\n",
    "    x0, y0, z0 : float \n",
    "        Initial values in three dimensional space\n",
    "    sigma, rho, beta : float \n",
    "        Parameters defining the lorenz attractor\n",
    "    tau : characteristic timescale in ms\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t : (num_steps) np.ndarray\n",
    "        Array of timepoints\n",
    "    (3, num_steps) np.ndarray\n",
    "        Integrated three-dimensional trajectory (x, y, z) of the Lorenz attractor\n",
    "    \"\"\"\n",
    "    def _lorenz_ode(point_of_interest, timepoint, sigma, rho, beta, tau):\n",
    "        \"\"\"\n",
    "        Fit the model with `spiketrains` data and apply the dimensionality\n",
    "        reduction on `spiketrains`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        point_of_interest : tuple\n",
    "            Tupel containing coordinates (x,y,z) in three dimensional space. \n",
    "        timepoint : a point of interest in time\n",
    "        dt : \n",
    "            Integration time step in ms.\n",
    "        num_steps : int\n",
    "            Number of integration steps -> max_time = dt*(num_steps-1).\n",
    "        sigma, rho, beta : float \n",
    "            Parameters defining the lorenz attractor\n",
    "        tau : characteristic timescale in ms\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_dot, y_dot, z_dot : float \n",
    "            Values of the lorenz attractor's partial derivatives\n",
    "            at the point x, y, z.\n",
    "        \"\"\"\n",
    "\n",
    "        x, y, z = point_of_interest\n",
    "\n",
    "        x_dot = (sigma*(y - x)) / tau\n",
    "        y_dot = (rho*x - y - x*z) / tau\n",
    "        z_dot = (x*y - beta*z) / tau\n",
    "        return x_dot, y_dot, z_dot\n",
    "\n",
    "    assert isinstance(num_steps, int), \"num_steps has to be integer\"\n",
    "    \n",
    "    t = dt*np.arange(num_steps)\n",
    "    poi = (x0, y0, z0)\n",
    "    return t, odeint(_lorenz_ode, poi, t, args=(sigma, rho, beta, tau)).T\n",
    "\n",
    "\n",
    "def random_projection(data, embedding_dimension, loc=0, scale=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Data to embed, shape=(M, N)\n",
    "    embedding_dimension : int\n",
    "        Embedding dimension, dimensionality of the space to project to.\n",
    "    loc : float or array_like of floats\n",
    "        Mean (“centre”) of the distribution.\n",
    "    scale : float or array_like of floats\n",
    "        Standard deviation (spread or “width”) of the distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray \n",
    "       Random (normal) projection of input data, shape=(dim, N)\n",
    "       \n",
    "    See Also\n",
    "    --------\n",
    "    np.random.normal()\n",
    "    \n",
    "    \"\"\"\n",
    "    if scale is None:\n",
    "        scale = 1 / np.sqrt(data.shape[0])\n",
    "    projection_matrix = np.random.normal(loc, scale, (embedding_dimension, data.shape[0]))\n",
    "    return np.dot(projection_matrix, data)\n",
    "\n",
    "\n",
    "def generate_spiketrains(instantaneous_rates, num_trials, timestep):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    instantaneous_rates : np.ndarray\n",
    "        Array containing time series.\n",
    "    timestep : \n",
    "        Sample period.\n",
    "    num_steps : int\n",
    "        Number of timesteps -> max_time = timestep*(num_steps-1).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    spiketrains : list of neo.SpikeTrains\n",
    "        List containing spiketrains of inhomogeneous Poisson\n",
    "        processes based on given instantaneous rates.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    spiketrains = []\n",
    "    for _ in range(num_trials):\n",
    "        spiketrains_per_trial = []\n",
    "        for inst_rate in instantaneous_rates:\n",
    "            anasig_inst_rate = neo.AnalogSignal(inst_rate, sampling_rate=1/timestep, units=pq.Hz)\n",
    "            spiketrains_per_trial.append(inhomogeneous_poisson_process(anasig_inst_rate))\n",
    "        spiketrains.append(spiketrains_per_trial)\n",
    "        \n",
    "    return spiketrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Harmonic Oscillator Example\n",
    "\n",
    "In this first example we apply the GPFA to spike train data derived from dynamics of a harmonic oscillator defined in a 2-dimensional latent variable space. The aim is to extract these 2-dimensional latent dynamics from the spike train data.\n",
    "\n",
    "### 2.1. Generate synthetic spike train data\n",
    "Here we generate 50-dimensional synthetic spike train data based on a trajectory of a 2-dimensional harmonic oscillator, as described in Section 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for the integration of the harmonic oscillator\n",
    "timestep = 1 * pq.ms\n",
    "trial_duration = 2 * pq.s\n",
    "num_steps = int((trial_duration.rescale('ms')/timestep).magnitude)\n",
    "\n",
    "# set parameters for spike train generation\n",
    "max_rate = 70 * pq.Hz\n",
    "np.random.seed(42)  # for visualization purposes, we want to get identical spike trains at any run\n",
    "\n",
    "# specify data size\n",
    "num_trials = 20\n",
    "num_spiketrains = 50\n",
    "\n",
    "# generate a low-dimensional trajectory\n",
    "times_oscillator, oscillator_trajectory_2dim = integrated_oscillator(\n",
    "    timestep.magnitude, num_steps=num_steps, x0=0, y0=1)\n",
    "times_oscillator = (times_oscillator*timestep.units).rescale('s')\n",
    "\n",
    "# random projection to high-dimensional space\n",
    "oscillator_trajectory_Ndim = random_projection(\n",
    "    oscillator_trajectory_2dim, embedding_dimension=num_spiketrains)\n",
    "\n",
    "# convert to instantaneous rate for Poisson process\n",
    "normed_traj = oscillator_trajectory_Ndim / oscillator_trajectory_Ndim.max()\n",
    "instantaneous_rates_oscillator = np.power(max_rate.magnitude, normed_traj)\n",
    "\n",
    "# generate spike trains\n",
    "spiketrains_oscillator = generate_spiketrains(\n",
    "    instantaneous_rates_oscillator, num_trials, timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the trajectory and the spike trains look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "ax1.set_title('2-dim Harmonic Oscillator')\n",
    "ax1.set_xlabel('time [s]')\n",
    "for i, y in enumerate(oscillator_trajectory_2dim):\n",
    "    ax1.plot(times_oscillator, y, label=f'dimension {i}')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_title('Trajectory in 2-dim space')\n",
    "ax2.set_xlabel('Dim 1')\n",
    "ax2.set_ylabel('Dim 2')\n",
    "ax2.set_aspect(1)\n",
    "ax2.plot(oscillator_trajectory_2dim[0], oscillator_trajectory_2dim[1])\n",
    "\n",
    "ax3.set_title(f'Projection to {num_spiketrains}-dim space')\n",
    "ax3.set_xlabel('time [s]')\n",
    "y_offset = oscillator_trajectory_Ndim.std() * 3\n",
    "for i, y in enumerate(oscillator_trajectory_Ndim):\n",
    "    ax3.plot(times_oscillator, y + i*y_offset)\n",
    "\n",
    "trial_to_plot = 0\n",
    "ax4.set_title(f'Raster plot of trial {trial_to_plot}')\n",
    "ax4.set_xlabel('Time (s)')\n",
    "ax4.set_ylabel('Spike train index')\n",
    "for i, spiketrain in enumerate(spiketrains_oscillator[trial_to_plot]):\n",
    "    ax4.plot(spiketrain, np.ones_like(spiketrain) * i, ls='', marker='|')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have generated 50-dimensional spike train data, derived from 2-dimensional latent dynamics, i.e., two cycles of circular rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Apply GPFA to the generated data\n",
    "Now we try to extract the original latent dynamics from the generated spike train data, by means of GPFA.\n",
    "\n",
    "We first initialize an instance of the `gpfa.GPFA()` class.\n",
    "One can specify some parameters for model fitting at this timing.\n",
    "Here we set the size of the bin for spike train binning to 20 ms, and the dimensionality of latent variables to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elephant.gpfa import GPFA\n",
    "\n",
    "\n",
    "# specify fitting parameters\n",
    "bin_size = 20 * pq.ms\n",
    "latent_dimensionality = 2\n",
    "\n",
    "gpfa_2dim = GPFA(bin_size=bin_size, x_dim=latent_dimensionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call the `fit()` method of the class, with the generated spike train data as input.\n",
    "This fits a GPFA model to the given data, yielding estimates of the model parameters that best explain the data, which are stored in the `params_estimated` attribute of the class.\n",
    "Here we use the first half of the trials for fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpfa_2dim.fit(spiketrains_oscillator[:num_trials//2])\n",
    "print(gpfa_2dim.params_estimated.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we transform the spike trains from the remaining half of the trials into tranjectories in the latent variable space, using the `transform()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = gpfa_2dim.transform(spiketrains_oscillator[num_trials//2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the extracted trajectories look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "linewidth_single_trial = 0.5\n",
    "color_single_trial = 'C0'\n",
    "alpha_single_trial = 0.5\n",
    "\n",
    "linewidth_trial_average = 2\n",
    "color_trial_average = 'C1'\n",
    "\n",
    "ax1.set_title('Original latent dynamics')\n",
    "ax1.set_xlabel('Dim 1')\n",
    "ax1.set_ylabel('Dim 2')\n",
    "ax1.set_aspect(1)\n",
    "ax1.plot(oscillator_trajectory_2dim[0], oscillator_trajectory_2dim[1])\n",
    "\n",
    "ax2.set_title('Latent dynamics extracted by GPFA')\n",
    "ax2.set_xlabel('Dim 1')\n",
    "ax2.set_ylabel('Dim 2')\n",
    "ax2.set_aspect(1)\n",
    "# single trial trajectories\n",
    "for single_trial_trajectory in trajectories:\n",
    "    ax2.plot(single_trial_trajectory[0], single_trial_trajectory[1], '-', lw=linewidth_single_trial, c=color_single_trial, alpha=alpha_single_trial)\n",
    "# trial averaged trajectory\n",
    "average_trajectory = np.mean(trajectories, axis=0)\n",
    "ax2.plot(average_trajectory[0], average_trajectory[1], '-', lw=linewidth_trial_average, c=color_trial_average, label='Trial averaged trajectory')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPFA successfuly exatracted, as the trial averaged trajectory, the two cycles of rotation in 2-dimensional latent space from the 50-dimensional spike train data.\n",
    "\n",
    "In the above application we split the trials into two halves and performed fitting and transforming separately on these two sets of trials.\n",
    "One can also simply perform fitting and transforming on the whole dataset to obtain latent trajectories for all trials.\n",
    "In such a senario, the `fit_transform()` method can be used to perform the fitting and transforming at once, as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we just reuse the existing instance of the GPFA() class as we use the same fitting parameters as before\n",
    "trajectories_all = gpfa_2dim.fit_transform(spiketrains_oscillator)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.set_title('Latent dynamics extracted by GPFA')\n",
    "ax1.set_xlabel('Dim 1')\n",
    "ax1.set_ylabel('Dim 2')\n",
    "ax1.set_aspect(1)\n",
    "for single_trial_trajectory in trajectories_all:\n",
    "    ax1.plot(single_trial_trajectory[0], single_trial_trajectory[1], '-', lw=linewidth_single_trial, c=color_single_trial, alpha=alpha_single_trial)\n",
    "average_trajectory = np.mean(trajectories_all, axis=0)\n",
    "ax1.plot(average_trajectory[0], average_trajectory[1], '-', lw=linewidth_trial_average, c=color_trial_average, label='Trial averaged trajectory')\n",
    "ax1.legend()\n",
    "\n",
    "trial_to_plot = 0\n",
    "ax2.set_title(f'Trajectory for trial {trial_to_plot}')\n",
    "ax2.set_xlabel('Time [s]')\n",
    "times_trajectory = np.arange(len(trajectories_all[trial_to_plot][0])) * bin_size.rescale('s')\n",
    "ax2.plot(times_trajectory, trajectories_all[0][0], c='C0', label=\"Dim 1, fitting with all trials\")\n",
    "ax2.plot(times_trajectory, trajectories[0][0], c='C0', alpha=0.2, label=\"Dim 1, fitting with a half of trials\")\n",
    "ax2.plot(times_trajectory, trajectories_all[0][1], c='C1', label=\"Dim 2, fitting with all trials\")\n",
    "ax2.plot(times_trajectory, trajectories[0][1], c='C1', alpha=0.2, label=\"Dim 2, fitting with a half of trials\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain almost the same latent dynamics, but single trial trajectories are slightly modified owing to an increased amount of the data used for fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lorentz System Example\n",
    "\n",
    "### 3.1. Generate sysnthetic spike train data\n",
    "Now we move on to the next example.\n",
    "Here we generate 50-dimensional synthetic spike train data based on a trajectory of a 3-dimensional Lorentz system.\n",
    "Note that, as we want to adopt a part of the trajectory where the double-wing structure of the attractor is fully developed as \"trial\", we drop off an initial part of the trajectory as \"transient\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for the integration of the Lorentz attractor\n",
    "timestep = 1 * pq.ms\n",
    "transient_duration = 10 * pq.s\n",
    "trial_duration = 30 * pq.s\n",
    "num_steps_transient = int((transient_duration.rescale('ms')/timestep).magnitude)\n",
    "num_steps = int((trial_duration.rescale('ms')/timestep).magnitude)\n",
    "\n",
    "# set parameters for spike train generation\n",
    "max_rate = 70 * pq.Hz\n",
    "np.random.seed(42)  # for visualization purposes, we want to get identical spike trains at any run\n",
    "\n",
    "# specify data\n",
    "num_trials = 20\n",
    "num_spiketrains = 50\n",
    "\n",
    "# calculate the oscillator\n",
    "times, lorentz_trajectory_3dim = integrated_lorenz(\n",
    "    timestep, num_steps=num_steps_transient+num_steps, x0=0, y0=1, z0=1.25)\n",
    "times = (times - transient_duration).rescale('s').magnitude\n",
    "times_trial = times[num_steps_transient:]\n",
    "\n",
    "# random projection\n",
    "lorentz_trajectory_Ndim = random_projection(\n",
    "    lorentz_trajectory_3dim[:, num_steps_transient:], embedding_dimension=num_spiketrains)\n",
    "\n",
    "# calculate instantaneous rate\n",
    "normed_traj = lorentz_trajectory_Ndim / lorentz_trajectory_Ndim.max()\n",
    "instantaneous_rates_lorentz = np.power(max_rate.magnitude, normed_traj)\n",
    "\n",
    "# generate spiketrains\n",
    "spiketrains_lorentz = generate_spiketrains(\n",
    "    instantaneous_rates_lorentz, num_trials, timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the obtained trajectory and the spike trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=(15, 10))\n",
    "ax1 = f.add_subplot(2, 2, 1)\n",
    "ax2 = f.add_subplot(2, 2, 2, projection='3d')\n",
    "ax3 = f.add_subplot(2, 2, 3)\n",
    "ax4 = f.add_subplot(2, 2, 4)\n",
    "\n",
    "ax1.set_title('Lorentz system')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "labels = ['x', 'y', 'z']\n",
    "for i, x in enumerate(lorentz_trajectory_3dim):\n",
    "    ax1.plot(times, x, label=labels[i])\n",
    "ax1.axvspan(-transient_duration.rescale('s').magnitude, 0, color='gray', alpha=0.1)\n",
    "ax1.text(-5, -20, 'Initial transient', ha='center')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_title(f'Trajectory in 3-dim space')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_ylabel('z')\n",
    "ax2.plot(lorentz_trajectory_3dim[0, :num_steps_transient],\n",
    "         lorentz_trajectory_3dim[1, :num_steps_transient],\n",
    "         lorentz_trajectory_3dim[2, :num_steps_transient], c='C0', alpha=0.3)\n",
    "ax2.plot(lorentz_trajectory_3dim[0, num_steps_transient:],\n",
    "         lorentz_trajectory_3dim[1, num_steps_transient:],\n",
    "         lorentz_trajectory_3dim[2, num_steps_transient:], c='C0')\n",
    "\n",
    "ax3.set_title(f'Projection to {num_spiketrains}-dim space')\n",
    "ax3.set_xlabel('Time [s]')\n",
    "y_offset = lorentz_trajectory_Ndim.std() * 3\n",
    "for i, y in enumerate(lorentz_trajectory_Ndim):\n",
    "    ax3.plot(times_trial, y + i*y_offset)\n",
    "\n",
    "trial_to_plot = 0\n",
    "ax4.set_title(f'Raster plot of trial {trial_to_plot}')\n",
    "ax4.set_xlabel('Time (s)')\n",
    "ax4.set_ylabel('Neuron id')\n",
    "for i, spiketrain in enumerate(spiketrains_lorentz[trial_to_plot]):\n",
    "    ax4.plot(spiketrain, np.ones(len(spiketrain)) * i, ls='', marker='|')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3-dimensional latent trajectory exhibit a charactistic structure of the Lorentz attractor: intermittent switching between rotations around two foci, which is difficult to recognize in the spike train data derived from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Apply GPFA to the generated data\n",
    "Now we apply the GPFA to the data, with the same bin size as before but with a latent dimensionality of 3 this time. We fit and transform all trials at once using the `fit_transform()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify fitting parameters\n",
    "bin_size = 20 * pq.ms\n",
    "latent_dimensionality = 3\n",
    "\n",
    "gpfa_3dim = GPFA(bin_size=bin_size, x_dim=latent_dimensionality)\n",
    "trajectories = gpfa_3dim.fit_transform(spiketrains_lorentz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the method worked in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15, 5))\n",
    "ax1 = f.add_subplot(1, 2, 1, projection='3d')\n",
    "ax2 = f.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "linewidth_single_trial = 0.5\n",
    "color_single_trial = 'C0'\n",
    "alpha_single_trial = 0.5\n",
    "\n",
    "linewidth_trial_average = 2\n",
    "color_trial_average = 'C1'\n",
    "\n",
    "ax1.set_title('Original latent dynamics')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('z')\n",
    "ax1.plot(lorentz_trajectory_3dim[0, num_steps_transient:],\n",
    "         lorentz_trajectory_3dim[1, num_steps_transient:],\n",
    "         lorentz_trajectory_3dim[2, num_steps_transient:])\n",
    "\n",
    "ax2.set_title('Latent dynamics extracted by GPFA')\n",
    "ax2.set_xlabel('Dim 1')\n",
    "ax2.set_ylabel('Dim 2')\n",
    "ax2.set_zlabel('Dim 3')\n",
    "# single trial trajectories\n",
    "for single_trial_trajectory in trajectories:\n",
    "    ax2.plot(single_trial_trajectory[0], single_trial_trajectory[1], single_trial_trajectory[2],\n",
    "             lw=linewidth_single_trial, c=color_single_trial, alpha=alpha_single_trial)\n",
    "# trial averaged trajectory\n",
    "average_trajectory = np.mean(trajectories, axis=0)\n",
    "ax2.plot(average_trajectory[0], average_trajectory[1], average_trajectory[2], lw=linewidth_trial_average, c=color_trial_average, label='Trial averaged trajectory')\n",
    "ax2.legend()\n",
    "ax2.view_init(azim=-5, elev=60)  # an optimal viewing angle for the trajectory extracted from our fixed spike trains\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the characteristic structure of the original latent dynamics was successfully extracted by GPFA.\n",
    "\n",
    "Let's take a closer look into the time series of the extracted latent variables, and compare them with the x, y, and z time series of the original Lorentz system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.set_title('Original latent dynamics')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "labels = ['x', 'y', 'z']\n",
    "for i, x in enumerate(lorentz_trajectory_3dim[:, num_steps_transient:]):\n",
    "    ax1.plot(times_trial, x, label=labels[i])\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_title('Latent dynamics extracted by GPFA')\n",
    "ax2.set_xlabel('Time [s]')\n",
    "for i, x in enumerate(average_trajectory):\n",
    "    ax2.plot(np.arange(len(x))*0.02, x, label=f'Dim {i+1}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the extracted dimension does not correspond solely to a single dimension of the original latent dynamics. In addition, the amplitude of Dim 3 is much smaller than the other two, reflecting the fact that the dimensionality of the original latent dynamics is close to 2, evident from the very similar time series of $x$ and $y$ of the original latent dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gpfa.GPFA()` class is compatible to the cross-validation functions of `sklearn.model_selection`, such that users can perform cross-validation to search for a set of parameters yielding best performance using these functions.\n",
    "\n",
    "Here we demonstrate a use of the `sklearn.model_selection.cross_val_score()` function to search for an optimal dimension of the latent variables for the spike train data derived from the Lorentz system.\n",
    "We vary the dimensionality between 1 and 5, and perform 3-fold cross-varidation for each dimensionality value, to obtain an estimate the log-likelihood of the data under the GPFA model with the given dimensionality.\n",
    "\n",
    "_Note: The following step is time consuming._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x_dims = [1, 2, 3, 4, 5]\n",
    "log_likelihoods = []\n",
    "for x_dim in x_dims:\n",
    "    gpfa_cv = GPFA(x_dim=x_dim)\n",
    "    # estimate the log-likelihood for the given dimensionality as the mean of the log-likelihoods from 3 cross-vailidation folds\n",
    "    cv_log_likelihoods = cross_val_score(gpfa_cv, spiketrains_lorentz, cv=3, n_jobs=3, verbose=True)\n",
    "    log_likelihoods.append(np.mean(cv_log_likelihoods)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the obtained log-likeliyhood as a function of the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(7, 5))\n",
    "plt.xlabel('Dimensionality of latent variables')\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.plot(x_dims, log_likelihoods, '.-')\n",
    "plt.plot(x_dims[np.argmax(log_likelihoods)], np.max(log_likelihoods), 'x', markersize=10, color='r')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red cross denotes the maximum log-likelihood, which is taken at the dimensionality of 2.\n",
    "This means that the best-fitting GPFA model is the one with a latent dimensionality of 2, which does not match the ground-truth dimensionality of 3 in this example.\n",
    "This \"underestimate\" of dimensionality would possibly be becouse the dimensionality of the Lorentz attractor is very close to 2 (to be precise, its Hausdorff dimension is estimated to be 2.06... [3]), and the stochastic \"encoding\" of the trajectory by spike trains would not allow for reprsenting such a subtle excess of dimensionality above 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Yu MB, Cunningham JP, Santhanam G, Ryu SI, Shenoy K V, Sahani M (2009) Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity. J. Neurophysiol. 102:614-635.\n",
    "\n",
    "[2] Pandarinath, C. et al. (2018) Inferring single-trial neural population dynamics using sequential auto-encoders. Nat. Methods 15:805–815.\n",
    "\n",
    "[3] Viswanath, D (2004) The fractal property of the Lorenz attractor. Physica D 190(1-2):115-128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "elephant_nixio",
   "language": "python",
   "name": "elephant_nixio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
